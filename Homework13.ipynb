{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZdFT85ZKlknhaZ3A6KEcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oleg-Niki/Learn-python/blob/main/Homework13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olTr_P-_apqo",
        "outputId": "c7a756ee-2dd3-4d2c-d735-da4c60528f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'wellness' occurs 22 times on the page.\n",
            "\n",
            "Words that occur at least 10 times:\n",
            "center : 15\n",
            "services : 14\n",
            "wellness : 10\n",
            "Dumped 309 words to wellness_words.txt\n"
          ]
        }
      ],
      "source": [
        "# Homework 13 Assignment\n",
        "# Oleg Nikitashin\n",
        "# Due date April 22, 2025 (23:59)\n",
        "\n",
        "# Part 1: Getting familiar with urllib.request\n",
        "link = 'https://collegeofsanmateo.edu/wellnesscenter'\n",
        "from urllib.request import urlopen\n",
        "\n",
        "response = urlopen(link)\n",
        "html_page = response.read().decode().lower()\n",
        "\n",
        "# How many times does 'wellness' occur?\n",
        "count_wellness = html_page.count('wellness')\n",
        "print(f\"'wellness' occurs {count_wellness} times on the page.\\n\")\n",
        "\n",
        "# Part 2: Implementing the Handlers\n",
        "\n",
        "from html.parser import HTMLParser\n",
        "import string\n",
        "\n",
        "class MyHTMLParser(HTMLParser):\n",
        "    \"\"\"\n",
        "    A subclass of HTMLParser that collects all text data,\n",
        "    filters out tokens containing punctuation, and can report\n",
        "    word frequencies and dump raw text to a file.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._words = []\n",
        "\n",
        "    def handle_data(self, data):\n",
        "        \"\"\"\n",
        "        Called for each block of text between tags.\n",
        "        Discards any token containing punctuation.\n",
        "        \"\"\"\n",
        "        for token in data.split():\n",
        "            # if token is purely alphabetic, collect it\n",
        "            if token and not any(ch in string.punctuation for ch in token):\n",
        "                self._words.append(token)\n",
        "\n",
        "    def frequency(self, n):\n",
        "        \"\"\"\n",
        "        Print all words that occur at least n times, in\n",
        "        alphabetical order with counts.\n",
        "        \"\"\"\n",
        "        from collections import Counter\n",
        "        ctr = Counter(self._words)\n",
        "        print(f\"Words that occur at least {n} times:\")\n",
        "        for word, cnt in sorted(ctr.items()):\n",
        "            if cnt >= n:\n",
        "                print(f\"{word} : {cnt}\")\n",
        "\n",
        "    def dump_data(self, filename):\n",
        "        \"\"\"\n",
        "        Write all collected words (one per line) to the given file.\n",
        "        \"\"\"\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            for w in self._words:\n",
        "                f.write(w + '\\n')\n",
        "        print(f\"Dumped {len(self._words)} words to {filename}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Fetch and parse the page again\n",
        "    resp = urlopen(link)\n",
        "    html = resp.read().decode().lower()\n",
        "\n",
        "    parser = MyHTMLParser()\n",
        "    parser.feed(html)\n",
        "\n",
        "    # Show frequency for words occurring >= 10 times\n",
        "    parser.frequency(10)\n",
        "\n",
        "    # Dump raw words to a file\n",
        "    parser.dump_data('wellness_words.txt')\n"
      ]
    }
  ]
}